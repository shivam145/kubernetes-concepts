# âš–ï¸ Kubernetes Resource Requests & Limits

## ðŸ”Ž What Are They?

Kubernetes schedules containers on nodes that have finite **CPU** and **Memory**.
But pods donâ€™t magically tell the cluster â€œI need X CPU and Y memoryâ€ unless you configure it.

Thatâ€™s where **requests** and **limits** come in:

* **Requests** â†’ the *minimum* amount of CPU/Memory a pod is guaranteed. Scheduler uses this to place pods.
* **Limits** â†’ the *maximum* amount of CPU/Memory a pod can consume. If it goes beyond, K8s throttles (CPU) or kills it (OOM).

---

## ðŸ½ï¸ Analogy

Imagine Kubernetes nodes as a **buffet hall** with limited plates (resources):

* **Requests = reserved plate size** ðŸ¥—
  You book at least this much food ahead of time. The waiter (scheduler) only seats you if enough is available.

* **Limits = maximum allowed food on your plate** ðŸ”
  You canâ€™t pile on forever. If you try to add more:

  * CPU: waiter makes you wait â†’ throttling.
  * Memory: plate breaks â†’ OOMKill.

---

## ðŸ› ï¸ How They Work in Practice

### CPU

* Measured in **cores (millicores)**.

  * `500m` = 0.5 CPU core.
  * `1000m` = 1 CPU core.

* Behavior:

  * If usage > limit â†’ throttled (not killed).
  * If usage < request â†’ doesnâ€™t matter, just gets what it needs.

### Memory

* Measured in **bytes (Mi, Gi, etc.)**.

* Behavior:

  * If usage > limit â†’ container is **OOMKilled** (killed and restarted).
  * If usage > request but < limit â†’ allowed, but scheduler didnâ€™t plan for it.

---

## ðŸ§ª Example Without Requests & Limits

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: no-limits
spec:
  containers:
    - name: app
      image: demo-app:latest
      resources: {}
```

âŒ Problems:

* Scheduler has no idea how much this pod needs.
* It may get packed tightly with others â†’ risk of OOM kills.
* A single greedy pod may hog CPU/memory, starving others.

---

## ðŸ§ª Example With Requests & Limits

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: with-limits
spec:
  containers:
    - name: app
      image: demo-app:latest
      resources:
        requests:
          cpu: "200m"
          memory: "256Mi"
        limits:
          cpu: "500m"
          memory: "512Mi"
```

âœ… Behavior:

* Pod wonâ€™t be scheduled unless a node has **200m CPU & 256Mi memory** free.
* Pod can burst up to **500m CPU & 512Mi memory**.
* Beyond this â†’ CPU throttled, Memory OOMKilled.

---

## ðŸ“Š How to Choose the Right Numbers

This is where people struggle most, so letâ€™s break it down.

### Step 1: Observe Baseline

* Run your app locally or in a test cluster with **no limits**.
* Send realistic load.
* Record average CPU/memory usage + peak usage.

### Step 2: Set Requests

* Requests â‰ˆ **baseline steady usage**.
* Rule: pick a value just above the *95th percentile* of steady load.

### Step 3: Set Limits

* Limits â‰ˆ **safe upper bound (peak + headroom)**.
* Usually 1.5x â€“ 2x the request for CPU, but **close to request for memory** (to avoid OOMs).

### Step 4: Tune Over Time

* Use **metrics-server**, Prometheus, or `kubectl top pod`.
* Adjust until pod avoids frequent throttling or OOMKills.

---

## ðŸ”¬ Before vs After Demo Scenario

We can build a **demo just like readiness/liveness**:

### 1. Before Case: No Requests & Limits

* Deploy app with CPU-hogging `/load` endpoint.
* Run load test â†’ pod hogs CPU, other pods suffer.

### 2. After Case: With Requests & Limits

* Deploy same app with `requests` + `limits`.
* Run load test again â†’

  * Pod throttled at limit (CPU) or killed at OOM (Memory).
  * Other pods remain stable.

---

## âš ï¸ Common Mistakes

1. **Setting requests too high** â†’ Pods canâ€™t schedule, cluster underutilized.
2. **Setting requests too low** â†’ Pod gets starved under load.
3. **Setting no limits** â†’ A noisy neighbor can take down the node.
4. **Too aggressive limits on memory** â†’ Frequent OOMKills.
5. **Equal request = limit always** â†’ removes burst capacity.

---

## ðŸŽ¯ Key Takeaways

* **Always set requests & limits** for production workloads.
* **CPU** over limit â†’ throttled.
* **Memory** over limit â†’ killed.
* Choose values based on **metrics + headroom**, not guesswork.
* Foundation for **autoscaling (HPA)** and **cluster stability**.

---
